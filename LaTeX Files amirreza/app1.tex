% Appendix 1
\chapter{الگوریتم FedAVG }

از مطرح‌ترین و ساده‌ترین روش‌های ادغام کردن پارامتر‌های ارسالی (به عنوان مثال وزن‌ها و بایاس‌های شبکه عصبی) توسط تجمیع کننده الگوریتم میان‌گیری از آن‌ها با وزن یکسان بین تمامی کارگران می‌باشد. این الگوریتم با نام \lr{Federated Averaging} برای اولین بار در \cite{b6} مطرح شده است. در نسخه‌های اولیه یادگیری فدرال، این الگوریتم به صورت متمرکز درون تجمیع کننده در انتهای هر دور از یادگیری اجرا می‌شود تا در نهایت تمام کارگران با وزن یکسان در فرآیند یادگیری سهیم باشند. در ادامه شبه‌کد دو تکه اصلی مورد نیاز از اجرای این الگوریتم در تجمیع‌کننده و کارگران آورده شده است.


از مهم‌ترین ایراداتی که می‌توان به این نوع الگوریتم گرفت این است که به علت ناهمگونی داده‌ها بین کارگران نباید در میانگین‌گیری وزن یکسانی به آنها داد. به همین دلیل طی سال‌های اخیرمدل‌های پیشرفته‌تری از این استراتژی معرفی شده است\cite{ref4}.


\begin{algorithm}[tbp]
    \caption{بروزرسانی مشترک: اجرا در هر کارگر}
    \label{alg:client_update}
    \begin{algorithmic}[1]
        \State \textbf{ورودی:} بردار وزن مدل $w$، (\lr{Local Mini Batch})اندازه دسته‌های کوچک محلی $B$
        \State \textbf{خروجی:} بردار وزن مدل به‌روزشده $w'$
        
        \Function{بروزرسانی-مشترک}{$w, B$}
            \State تقسیم $P_k$ به دسته‌هایی به اندازه $B$: $بچها \gets \text{تقسیم\_به\_بچها}(P_k, B)$
            
            \For{$i = 1$ تا $E$} \Comment{عبورهای آموزشی محلی}
                \For{$هر دسته$ در $دسته‌ها$}
                    \State $w \gets w - \eta \cdot \nabla f(w,دسته)$ \Comment{بروزرسانی وزن‌های مدل}
                \EndFor
            \EndFor
            
            \State \Return $w$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[tbp]
    \caption{میانگین‌گیری مشترک: اجرا در سرور}
    \label{alg:federated_averaging}
    \begin{algorithmic}[1]
        \State \textbf{ورودی:} نرخ یادگیری جهانی $\eta$، تعداد کارگر‌ها در هر دور $C$، تعداد عبور آموزشی محلی $E$، اندازه مینی‌بچ محلی $B$
        \State \textbf{خروجی:} بردار وزن مدل میانگین $w_{\text{avg}}$
        
        \Function{میانگین‌گیری-مشترک}{$\eta, C, E, B$}
            \State مقداردهی اولیه بردار وزن مدل: $w \gets w_0$
            
            \For{$t = 1$ تا $\infty$} \Comment{دوره‌های آموزشی}
                \State انتخاب به صورت تصادفی $C$ کارگر: $کارگر‌های\_انتخاب‌شده \gets \text{انتخاب\_کارگر‌ها}(C)$
                
                \For{$k$ در $کارگر‌های\_انتخاب‌شده$}
                    \State انجام بروزرسانی مشترک برای کارگر $k$: $w_k \gets \text{بروزرسانی-مشترک}(w, B)$
                    \State بروزرسانی بردار وزن مدل برای کارگر $k$: $w \gets \text{تجمیع\_وزن‌ها}(w, w_k)$
                \EndFor
                
                \State محاسبه میانگین وزن‌های تمام کارگر‌ها: $w_{\text{avg}} \gets \text{محاسبه\_میانگین\_وزن‌ها}(w, C)$
            \EndFor
            
            \State \Return $w_{\text{avg}}$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

